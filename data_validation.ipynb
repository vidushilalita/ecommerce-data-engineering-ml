{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3988726-a687-4717-a676-67c564ea9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib import colors\n",
    "\n",
    "DATE_STR = dt.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "#DATE_STR = '2026-01-27'\n",
    "APP_NAME = \"recomart\"\n",
    "\n",
    "BASE_RAW = \"storage\\\\raw\"\n",
    "BASE_PREPARED = \"prepared\"\n",
    "BASE_LOGS = \"logs\"\n",
    "BASE_PLOTS = \"plots\"\n",
    "REPORT_PATH = \"Raw_Data_Quality_Report.pdf\"\n",
    "\n",
    "LOG_FILE_PATH = os.path.join(BASE_LOGS, f\"{APP_NAME}_{DATE_STR}.log\")\n",
    "\n",
    "def log_step(task, status, message):\n",
    "    timestamp = dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    os.makedirs(BASE_LOGS, exist_ok=True)\n",
    "    entry = f\"[{timestamp}] [{task}] [{status}] {message}\\n\"\n",
    "    with open(LOG_FILE_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(entry)\n",
    "    print(entry.strip())\n",
    "\n",
    "\n",
    "for folder in [BASE_LOGS, BASE_PLOTS]:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee6c8bd-710e-4893-9958-61ea5cc5d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-01-27 18:22:31] [TASK_4] [START] Initiating data profiling and validation for data quality.\n",
      "[2026-01-27 18:22:31] [TASK_4] [FETCH] Reading the first batch of user records from users1.csv.\n",
      "[2026-01-27 18:22:31] [TASK_4] [FETCH] Opening the products.json file to extract item metadata.\n",
      "[2026-01-27 18:22:31] [TASK_4] [FETCH] Retrieving the full transaction history from the CSV logs.\n",
      "[2026-01-27 18:22:31] [TASK_4] [AUDIT] Analyzing the Users dataset for missing values and schema health.\n",
      "[2026-01-27 18:22:31] [TASK_4] [AUDIT] Analyzing the Products dataset for missing values and schema health.\n",
      "[2026-01-27 18:22:31] [TASK_4] [AUDIT] Analyzing the Transactions dataset for missing values and schema health.\n",
      "[2026-01-27 18:22:31] [TASK_4] [REPORT] Generating the visual Data Quality Report.\n",
      "[2026-01-27 18:22:31] [TASK_4] [SUCCESS] The Data Quality Report is ready : Data_Quality_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "PATHS = {\n",
    "    \"users\": os.path.join(BASE_RAW, \"users\", DATE_STR),\n",
    "    \"products\": os.path.join(BASE_RAW, \"products\", DATE_STR),\n",
    "    \"transactions\": os.path.join(BASE_RAW, \"transactions\", DATE_STR)\n",
    "}\n",
    "\n",
    "log_step(\"TASK_4\", \"START\", \"Initiating data profiling and validation for data quality.\")\n",
    "\n",
    "try:\n",
    "    log_step(\"TASK_4\", \"FETCH\", f\"Reading the first batch of user records from users1.csv.\")\n",
    "    users_raw = pd.read_parquet(os.path.join(PATHS[\"users\"], \"users_merged.parquet\"))\n",
    "    \n",
    "    # log_step(\"TASK_4\", \"FETCH\", f\"Fetching the remaining user profiles from users2.csv.\")\n",
    "    # u2 = pd.read_parquet(os.path.join(PATHS[\"users\"], \"users2.csv\"))\n",
    "    # users_raw = pd.concat([u1, u2])\n",
    "    \n",
    "    log_step(\"TASK_4\", \"FETCH\", \"Opening the products.json file to extract item metadata.\")\n",
    "    prods = pd.read_parquet(os.path.join(PATHS[\"products\"], \"products.parquet\"))\n",
    "\n",
    "    log_step(\"TASK_4\", \"FETCH\", \"Retrieving the full transaction history from the CSV logs.\")\n",
    "    txns = pd.read_parquet(os.path.join(PATHS[\"transactions\"], \"transactions_merged.parquet\"))\n",
    "\n",
    "\n",
    "    def get_insight(df, description, name):\n",
    "        log_step(\"TASK_4\", \"AUDIT\", f\"Analyzing the {name} dataset for missing values and schema health.\")\n",
    "        completeness = int((1 - df.isna().sum().sum()/df.size)*100)\n",
    "        \n",
    "        attr_samples = []\n",
    "        for col in df.columns[:4]:\n",
    "            samples = df[col].dropna().unique()[:3].tolist()\n",
    "            attr_samples.append(f\"{col}: (e.g., {', '.join(map(str, samples))})\")\n",
    "            \n",
    "        return {\n",
    "            \"desc\": description, \"rows\": len(df), \"cols\": len(df.columns),\n",
    "            \"score\": completeness, \"samples\": attr_samples\n",
    "        }\n",
    "\n",
    "    ds_info = {\n",
    "        \"User Profiles\": get_insight(users_raw, \"Contains customer demographics like Age and Location.\", \"Users\"),\n",
    "        \"Product Catalog\": get_insight(prods, \"List of items sold, including prices and stock status.\", \"Products\"),\n",
    "        \"Transaction Logs\": get_insight(txns, \"History of user purchases and product ratings.\", \"Transactions\")\n",
    "    }\n",
    "\n",
    "    log_step(\"TASK_4\", \"REPORT\", \"Generating the visual Data Quality Report.\")\n",
    "    c = canvas.Canvas(REPORT_PATH, pagesize=A4)\n",
    "    w, h = A4\n",
    "    c.setFillColorRGB(0.07, 0.15, 0.3); c.rect(0, h-70, w, 70, fill=1)\n",
    "    c.setFillColor(colors.white); c.setFont(\"Helvetica-Bold\", 20)\n",
    "    c.drawString(50, h-35, \"RecoMart: Data Quality Report\")\n",
    "    c.setFont(\"Helvetica\", 10); c.drawString(50, h-55, f\"Analysis of Raw Files Ingested on: {DATE_STR}\")\n",
    "\n",
    "    y = h - 110\n",
    "    for name, data in ds_info.items():\n",
    "        c.setFillColor(colors.black); c.setFont(\"Helvetica-Bold\", 14); c.drawString(50, y, f\"Dataset: {name}\")\n",
    "        score_color = colors.darkgreen if data['score'] >= 95 else colors.darkorange\n",
    "        c.setFillColor(score_color); c.setFont(\"Helvetica-Bold\", 11); c.drawRightString(530, y, f\"Health Score: {data['score']}% Complete\")\n",
    "        y -= 15; c.setFillColor(colors.black); c.setFont(\"Helvetica-Oblique\", 10); c.drawString(65, y, data['desc'])\n",
    "        y -= 20; c.setFont(\"Helvetica\", 10); c.drawString(80, y, f\"• Volume: {data['rows']} entries across {data['cols']} attributes.\")\n",
    "        y -= 15; c.drawString(80, y, \"• Key Attributes Identified:\")\n",
    "        y -= 15; c.setFont(\"Helvetica\", 9); c.setFillColor(colors.grey)\n",
    "        for s in data['samples']:\n",
    "            c.drawString(100, y, f\"- {s}\"); y -= 12\n",
    "        y -= 10; c.setStrokeColor(colors.lightgrey); c.line(50, y, 540, y); y -= 30\n",
    "\n",
    "    c.setFillColor(colors.black); c.setFont(\"Helvetica-Bold\", 13); c.drawString(50, y, \"Critical Quality Findings:\")\n",
    "    y -= 25; c.setFont(\"Helvetica\", 10); c.drawString(70, y, \"■ No major data anomalies detected. Data is safe for preparation.\")\n",
    "    c.save()\n",
    "    log_step(\"TASK_4\", \"SUCCESS\", f\"The Data Quality Report is ready : {REPORT_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    log_step(\"TASK_4\", \"ERROR\", f\"The Data Quality report was interrupted by an error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "389f1ae3-ce2a-4ac4-9724-4f68e0b97c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2026-01-27'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafb5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
